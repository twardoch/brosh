This file is a merged representation of a subset of the codebase, containing files not matching ignore patterns, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching these patterns are excluded: varia, .specstory, AGENT.md, CLAUDE.md, PLAN.md, SPEC.md, llms.txt, .cursorrules
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.github/
  workflows/
    push.yml
    release.yml
src/
  brosh/
    __init__.py
    __main__.py
    brosh.py
    browser.py
    capture.py
    cli.py
    image.py
    mcp.py
    models.py
    tool.py
tests/
  test_package.py
.cursorindexingignore
.gitignore
.pre-commit-config.yaml
CHANGELOG.md
cleanup.sh
LICENSE
package.toml
pyproject.toml
pyrightconfig.json
README.md
TODO.md
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="src/brosh/__init__.py">
#!/usr/bin/env python3
# this_file: src/brosh/__init__.py

"""Browser screenshot _tool using Playwright async API."""

from .cli import BrowserScreenshotCLI
from .models import ImageFormat
from .tool import BrowserScreenshotTool

__version__ = "0.1.0"
__all__ = ["BrowserScreenshotTool", "BrowserScreenshotCLI", "ImageFormat"]
</file>

<file path="src/brosh/__main__.py">
#!/usr/bin/env python3
# this_file: src/brosh/__main__.py

"""CLI entry point for brosh."""

import fire

from .cli import BrowserScreenshotCLI


def main():
    """Main entry point for the brosh CLI."""
    fire.Fire(BrowserScreenshotCLI)


if __name__ == "__main__":
    main()
</file>

<file path="src/brosh/browser.py">
#!/usr/bin/env python3
# this_file: src/brosh/browser.py

"""Browser management utilities for brosh."""

import asyncio
import os
import platform
import subprocess
from typing import Optional, Tuple

from loguru import logger
from playwright.async_api import async_playwright


class BrowserManager:
    """Manages browser detection, launching, and connection."""

    def __init__(self, connection_timeout: int = 30):
        """Initialize browser manager.
        
        Args:
            connection_timeout: Timeout for browser connections in seconds
        """
        self.connection_timeout = connection_timeout
        self.debug_ports = {
            "chromium": 9222,
            "msedge": 9223,
            "webkit": 9225,
        }

    def get_screen_dimensions(self) -> tuple[int, int]:
        """Get main screen dimensions in logical pixels for browser sizing.

        Returns:
            Tuple of (width, height) in logical pixels (CSS pixels)

        """
        if platform.system() == "Darwin":  # macOS
            try:
                # Get physical resolution
                result = subprocess.run(
                    ["system_profiler", "SPDisplaysDataType"],
                    capture_output=True,
                    text=True,
                    check=True,
                    timeout=10,
                )
                for line in result.stdout.split("\n"):
                    if "Resolution:" in line:
                        parts = line.split()
                        for i, part in enumerate(parts):
                            if "x" in part and i > 0:
                                physical_width = int(parts[i - 1])
                                physical_height = int(parts[i + 1])

                                # Check if it's a Retina display
                                if "Retina" in line or physical_width >= 2560:
                                    # Retina: logical = physical / 2
                                    return (
                                        physical_width // 2,
                                        physical_height // 2,
                                    )
                                else:
                                    # Non-Retina: logical = physical
                                    return physical_width, physical_height
                        break

            except (
                subprocess.CalledProcessError,
                ValueError,
                IndexError,
                subprocess.TimeoutExpired,
            ) as e:
                logger.warning(f"Failed to get macOS screen dimensions: {e}")

        elif platform.system() == "Windows":
            try:
                import tkinter

                root = tkinter.Tk()
                # Get logical size (accounts for DPI scaling automatically)
                width = root.winfo_screenwidth()
                height = root.winfo_screenheight()
                root.destroy()
                return width, height
            except ImportError:
                logger.warning("tkinter not available on Windows")

        # Default fallback for unknown systems or errors
        return 1440, 900  # Common laptop logical resolution

    def get_browser_name(self, app: str = "") -> str:
        """Determine browser name from app parameter or OS default.

        Priority order: Chrome > Edge > Safari (macOS only)
        Firefox support removed per user request.

        Args:
            app: User-specified browser preference

        Returns:
            Browser name compatible with Playwright

        """
        if bool(app):
            app_lower = app.lower()
            if "chrome" in app_lower:
                return "chromium"
            elif "edge" in app_lower:
                return "msedge"
            elif "safari" in app_lower and platform.system() == "Darwin":
                return "webkit"

        # Auto-detect available browser in priority order
        if platform.system() == "Darwin":  # macOS
            # Priority: Chrome > Edge > Safari
            for browser in ["chromium", "msedge", "webkit"]:
                if self.is_browser_available(browser):
                    return browser
        else:  # Windows/Linux
            # Priority: Chrome > Edge
            for browser in ["chromium", "msedge"]:
                if self.is_browser_available(browser):
                    return browser

        # Fallback
        return "chromium"

    def is_browser_available(self, browser_name: str) -> bool:
        """Check if browser is installed and available.

        Args:
            browser_name: Browser name to check

        Returns:
            True if browser is available

        """
        paths = self.get_browser_paths(browser_name)
        
        # Check if any path exists
        for path in paths:
            if os.path.exists(path):
                return True
        return False

    def get_browser_paths(self, browser_name: str) -> list:
        """Get possible paths for a browser.
        
        Args:
            browser_name: Browser name
            
        Returns:
            List of possible paths
        """
        if browser_name == "chromium":
            return [
                "/Applications/Google Chrome.app/Contents/MacOS/Google Chrome",
                "/Applications/Chromium.app/Contents/MacOS/Chromium",
                "/usr/bin/google-chrome",
                "/usr/bin/chromium-browser",
                "/opt/google/chrome/chrome",
                ("C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe"),
                ("C:\\Program Files (x86)\\Google\\Chrome\\Application\\chrome.exe"),
            ]
        elif browser_name == "msedge":
            return [
                ("/Applications/Microsoft Edge.app/Contents/MacOS/Microsoft Edge"),
                ("C:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe"),
                ("C:\\Program Files\\Microsoft\\Edge\\Application\\msedge.exe"),
            ]
        elif browser_name == "webkit":
            return ["/Applications/Safari.app/Contents/MacOS/Safari"]
        else:
            return []

    def find_browser_path(self, browser_name: str) -> str | None:
        """Find the path to the specified browser executable.

        Args:
            browser_name: Name of the browser to find

        Returns:
            Path to browser executable or None if not found

        """
        paths = self.get_browser_paths(browser_name)
        
        for path in paths:
            if os.path.exists(path):
                return path
        return None

    async def get_browser_instance(
        self, playwright, browser_name: str, width: int, height: int, zoom: int
    ) -> tuple:
        """Get browser instance, connecting to user's actual browser.

        This method tries to connect to the user's existing browser in
        debug mode. If that fails, it will attempt to restart the browser
        in debug mode.

        Args:
            playwright: Playwright instance
            browser_name: Name of browser to use
            width: Viewport width
            height: Viewport height
            zoom: Zoom level percentage

        Returns:
            Tuple of (browser, context, page)

        Raises:
            RuntimeError: If browser connection fails

        """
        debug_port = self.debug_ports.get(browser_name, 9222)

        # Try to connect to existing browser instance first
        browser = None
        try:
            if browser_name in ["chromium", "msedge"]:
                browser = await playwright.chromium.connect_over_cdp(
                    f"http://localhost:{debug_port}",
                    timeout=self.connection_timeout * 1000,
                )

            if browser:
                # Don't set device_scale_factor - let browser use natural scaling
                # Use default height if height is -1 (capture entire page)
                viewport_height = height if height != -1 else 900
                context = await browser.new_context(
                    viewport={"width": width, "height": viewport_height}
                )
                page = await context.new_page()

                # Apply zoom via CSS instead of device scale factor
                if zoom != 100:
                    await page.add_init_script(f"""
                        document.addEventListener('DOMContentLoaded', () => {{
                            document.body.style.zoom = '{zoom}%';
                        }});
                    """)

                return browser, context, page
        except Exception as e:
            logger.info(f"Could not connect to existing browser: {e}")
            logger.info("Attempting to start browser in debug mode...")

        # If we can't connect, try to launch the user's actual browser
        # in debug mode (not Playwright's browser)
        browser = None

        if browser_name == "chromium":
            # Try to launch user's Chrome in debug mode
            chrome_paths = self.get_browser_paths("chromium")

            for chrome_path in chrome_paths:
                if await self.launch_browser_and_connect(
                    chrome_path,
                    debug_port,
                    width,
                    height,
                    playwright.chromium,
                    "chromium",
                ):
                    browser = await playwright.chromium.connect_over_cdp(
                        f"http://localhost:{debug_port}"
                    )
                    break

        elif browser_name == "msedge":
            # Try to launch user's Edge in debug mode
            edge_paths = self.get_browser_paths("msedge")

            for edge_path in edge_paths:
                if await self.launch_browser_and_connect(
                    edge_path,
                    debug_port,
                    width,
                    height,
                    playwright.chromium,
                    "msedge",
                ):
                    browser = await playwright.chromium.connect_over_cdp(
                        f"http://localhost:{debug_port}"
                    )
                    break

        elif browser_name == "webkit":
            # For Safari, we need to enable "Develop" menu first
            logger.info("For Safari: Enable Develop menu in Preferences > Advanced")
            logger.info("Then enable 'Allow Remote Automation' in Develop menu")
            # Safari doesn't support remote debugging like Chrome/Firefox
            # Fall back to launching webkit
            browser = await playwright.webkit.launch(headless=False)

        if not browser:
            raise RuntimeError(
                f"Could not connect to or launch {browser_name} browser. "
                "Please ensure the browser is installed and try again."
            )

        # Create context without device scale factor to avoid scaling issues
        # Use default height if height is -1 (capture entire page)
        viewport_height = height if height != -1 else 900
        context = await browser.new_context(viewport={"width": width, "height": viewport_height})
        page = await context.new_page()

        # Apply zoom via CSS instead of device scale factor
        if zoom != 100:
            await page.add_init_script(f"""
                document.addEventListener('DOMContentLoaded', () => {{
                    document.body.style.zoom = '{zoom}%';
                }});
            """)

        return browser, context, page

    async def launch_browser_and_connect(
        self,
        browser_path: str,
        debug_port: int,
        width: int,
        height: int,
        playwright_browser,
        browser_type: str,
    ) -> bool:
        """Launch browser with debug mode and test connection.

        Args:
            browser_path: Path to browser executable
            debug_port: Debug port to use
            width: Window width
            height: Window height
            playwright_browser: Playwright browser module
            browser_type: Type of browser (chromium, msedge)

        Returns:
            True if successfully launched and connected

        """
        if not os.path.exists(browser_path):
            logger.debug(f"Browser path does not exist: {browser_path}")
            return False

        try:
            # Kill existing processes with same debug port - more aggressive cleanup
            try:
                if platform.system() == "Darwin":  # macOS
                    # Kill by process name and port
                    subprocess.run(
                        ["pkill", "-f", f"remote-debugging-port={debug_port}"],
                        capture_output=True,
                        timeout=5,
                    )
                    # Also try killing by process name
                    if "Chrome" in browser_path:
                        subprocess.run(
                            ["pkill", "-f", "Google Chrome.*remote-debugging"],
                            capture_output=True,
                            timeout=5,
                        )
                else:  # Windows/Linux
                    subprocess.run(
                        ["taskkill", "/F", "/IM", "chrome.exe"],
                        capture_output=True,
                        timeout=5,
                    )
            except Exception as e:
                logger.debug(f"Process cleanup warning: {e}")

            await asyncio.sleep(2)  # Give processes time to die

            # Launch browser with remote debugging
            if browser_type in ["chromium", "msedge"]:
                args = [
                    browser_path,
                    f"--remote-debugging-port={debug_port}",
                    "--no-startup-window",
                    "--noerrdialogs",
                    "--no-user-gesture-required",
                    "--no-network-profile-warning",
                    "--no-first-run",
                    "--no-experiments",
                    "--no-default-browser-check",
                    "--remote-debug-mode",
                    "--disable-web-security",
                    "--disable-features=VizDisplayCompositor",
                    "--disable-background-timer-throttling",
                    "--disable-backgrounding-occluded-windows",
                    "--disable-renderer-backgrounding",
                    "--disable-infobars",
                    "--disable-extensions",
                    "--disable-sync",
                    "--disable-translate",
                    "--disable-background-networking",
                    f"--window-size={width},{height}",
                    "--user-data-dir=/tmp/chrome-debug-brosh",
                ]
            else:
                return False

            logger.info(f"Launching {browser_type} with debug port {debug_port}")
            process = subprocess.Popen(
                args, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL
            )

            # Wait for browser to start and test connection more robustly
            for attempt in range(10):  # More attempts
                await asyncio.sleep(1)  # Shorter intervals
                try:
                    if browser_type in ["chromium", "msedge"]:
                        test_browser = await playwright_browser.connect_over_cdp(
                            f"http://localhost:{debug_port}", timeout=5000
                        )
                    else:
                        return False

                    # Test that we can actually create a page
                    test_context = await test_browser.new_context()
                    test_page = await test_context.new_page()
                    await test_page.close()
                    await test_context.close()
                    await test_browser.close()

                    logger.info(
                        f"Successfully launched {browser_type} at {browser_path}"
                    )
                    return True

                except Exception as e:
                    logger.debug(f"Connection attempt {attempt + 1}/10 failed: {e}")
                    if attempt == 9:  # Last attempt
                        # Kill the process we started if it's still running
                        try:
                            process.terminate()
                            await asyncio.sleep(1)
                            if process.poll() is None:
                                process.kill()
                        except Exception:
                            pass
                        return False
                    continue

        except Exception as e:
            logger.error(f"Failed to launch {browser_type} at {browser_path}: {e}")
            return False

        return False  # Explicit return for all paths

    async def cleanup_browser(self, page, context, browser) -> None:
        """Clean up browser resources safely.

        Args:
            page: Playwright page instance
            context: Playwright context instance
            browser: Playwright browser instance

        """
        try:
            if page:
                await page.close()
        except Exception as e:
            logger.warning(f"Failed to close page: {e}")

        try:
            if context:
                await context.close()
        except Exception as e:
            logger.warning(f"Failed to close context: {e}")

        try:
            if hasattr(browser, "_browser") and browser._browser:
                await browser.close()
        except Exception as e:
            logger.warning(f"Failed to close browser: {e}")

    def get_browser_args(self, browser_type: str, width: int, height: int, debug_port: int) -> list:
        """Get browser launch arguments.
        
        Args:
            browser_type: Type of browser
            width: Window width
            height: Window height
            debug_port: Debug port
            
        Returns:
            List of command line arguments
        """
        if browser_type in ["chromium", "msedge"]:
            return [
                f"--remote-debugging-port={debug_port}",
                "--no-startup-window",
                "--noerrdialogs",
                "--no-user-gesture-required",
                "--no-network-profile-warning",
                "--no-first-run",
                "--no-experiments",
                "--no-default-browser-check",
                "--disable-web-security",
                "--disable-features=VizDisplayCompositor",
                "--disable-background-timer-throttling",
                "--disable-backgrounding-occluded-windows",
                "--disable-renderer-backgrounding",
                "--disable-infobars",
                "--disable-extensions",
                "--disable-sync",
                "--disable-translate",
                "--disable-background-networking",
                f"--window-size={width},{height}",
                "--user-data-dir=/tmp/chrome-debug-brosh",
            ]
        return []
</file>

<file path="src/brosh/capture.py">
#!/usr/bin/env python3
# this_file: src/brosh/capture.py

"""Screenshot capture logic for brosh."""

import asyncio
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple
from urllib.parse import urlparse

from loguru import logger
from playwright.async_api import TimeoutError as PlaywrightTimeoutError

from .image import ImageProcessor


class CaptureManager:
    """Manages screenshot capture operations."""

    def __init__(self, page_timeout: int = 60, screenshot_timeout: int = 10):
        """Initialize capture manager.
        
        Args:
            page_timeout: Page load timeout in seconds
            screenshot_timeout: Screenshot capture timeout in seconds
        """
        self.page_timeout = page_timeout
        self.screenshot_timeout = screenshot_timeout
        self.image_processor = ImageProcessor()

    def validate_inputs(
        self, url: str, zoom: int, scroll_step: int, scale: int, format: str
    ) -> None:
        """Validate input parameters.

        Args:
            url: URL to validate
            zoom: Zoom level to validate
            scroll_step: Scroll step to validate
            scale: Scale to validate
            format: Format to validate

        Raises:
            ValueError: For invalid parameters

        """
        if not url or not url.startswith(("http://", "https://")):
            raise ValueError(f"Invalid URL: {url}")

        if not (10 <= zoom <= 500):
            raise ValueError(f"Zoom must be between 10-500%: {zoom}")

        if not (10 <= scroll_step <= 200):
            raise ValueError(f"Scroll step must be between 10-200%: {scroll_step}")

        if not (10 <= scale <= 200):
            raise ValueError(f"Scale must be between 10-200%: {scale}")

        if format.lower() not in ["png", "jpg", "apng"]:
            raise ValueError(f"Unsupported format: {format}. Use: png, jpg, apng")

    async def capture_screenshots(
        self,
        page,
        url: str,
        domain: str,
        output_path: Path,
        width: int,
        height: int,
        scroll_step: int,
        scale: int,
        img_format: str,
        anim_spf: float,
        temp_png_paths: list[Path],
        html: bool = False,
        max_frames: int = 0,
        from_selector: str = "",
    ) -> tuple[list[str], dict[str, str]]:
        """Capture all screenshots for the page.

        Args:
            page: Playwright page instance
            url: URL being captured
            domain: Domain name for filenames
            output_path: Output directory
            width: Viewport width
            height: Viewport height
            scroll_step: Scroll step percentage
            scale: Image scale percentage
            img_format: Output format
            anim_spf: Animation seconds per frame
            temp_png_paths: List to store temp PNG paths
            html: Whether to capture HTML/selectors
            max_frames: Maximum number of frames to capture
            from_selector: CSS selector to scroll to before starting

        Returns:
            Tuple of (saved file paths, html data dict)

        """
        saved_paths = []
        html_data = {}

        # Navigate to URL with timeout and retries
        try:
            logger.info(f"Navigating to {url}")
            await page.goto(
                url,
                wait_until="domcontentloaded",
                timeout=self.page_timeout * 1000,
            )
            await asyncio.sleep(3)  # Additional wait for dynamic content
        except PlaywrightTimeoutError:
            logger.warning("Page load timeout, proceeding anyway")
        except Exception as e:
            raise RuntimeError(f"Failed to navigate to {url}: {e}")

        # Handle from_selector - scroll to element before starting
        start_position = 0
        if from_selector:
            try:
                logger.info(f"Scrolling to element: {from_selector}")
                # Scroll element into view and get its position
                start_position = await page.evaluate(f"""
                    (() => {{
                        const element = document.querySelector('{from_selector}');
                        if (element) {{
                            element.scrollIntoView({{behavior: 'instant', block: 'start'}});
                            return element.getBoundingClientRect().top + window.pageYOffset;
                        }}
                        return 0;
                    }})()
                """)
                await asyncio.sleep(1)  # Wait for scroll to complete
                logger.info(f"Starting capture from position: {start_position}px")
            except Exception as e:
                logger.warning(f"Failed to find selector '{from_selector}': {e}, starting from top")
                start_position = 0

        # Get total page height for scroll calculation
        try:
            total_height = await page.evaluate("document.documentElement.scrollHeight")
            # Handle height == -1 to capture entire page
            if height == -1:
                viewport_height = await page.evaluate("window.innerHeight")
                logger.info(f"Capturing entire page - height: {total_height}px, viewport: {viewport_height}px")
            else:
                viewport_height = height
                logger.info(f"Page height: {total_height}px, viewport: {viewport_height}px")
        except Exception as e:
            raise RuntimeError(f"Failed to get page dimensions: {e}")

        # Calculate all scroll positions based on step size
        scroll_positions = []
        current_pos = start_position
        while current_pos < total_height:
            scroll_positions.append(int(current_pos))
            current_pos += int(viewport_height * scroll_step / 100)

        # Limit frames if max_frames is specified
        if max_frames > 0:
            scroll_positions = scroll_positions[:max_frames]

        logger.info(f"Will capture {len(scroll_positions)} screenshots")

        # Generate timestamp for filename
        now = datetime.now()
        timestamp = now.strftime("%y%m%d-%H%M%S")

        # Capture screenshots at each scroll position
        for i, scroll_pos in enumerate(scroll_positions):
            try:
                # Scroll to the calculated position
                await page.evaluate(f"window.scrollTo(0, {scroll_pos})")
                await asyncio.sleep(0.8)  # Wait for scroll animation and content load

                # Calculate scroll percentage for filename
                scroll_percentage = min(int((scroll_pos / total_height) * 10000), 9999)

                # Get semantic section ID based on visible content
                section_id = await self.get_section_id(page)

                # Generate descriptive filename
                if img_format == "apng":
                    # For APNG, save as PNG first, convert later
                    filename = (
                        f"{domain}-{timestamp}-{scroll_percentage:05d}-{section_id}.png"
                    )
                    filepath = output_path / filename
                    temp_png_paths.append(filepath)
                else:
                    filename = (
                        f"{domain}-{timestamp}-{scroll_percentage:05d}-"
                        f"{section_id}.{img_format}"
                    )
                    filepath = output_path / filename

                # Capture the visible area screenshot with timeout
                try:
                    await page.screenshot(
                        path=str(filepath),
                        full_page=False,
                        timeout=self.screenshot_timeout * 1000,
                    )
                except PlaywrightTimeoutError:
                    logger.warning(
                        f"Screenshot timeout for position {scroll_pos}, skipping"
                    )
                    continue

                # Apply scaling if requested
                if scale != 100:
                    self.image_processor.scale_image(filepath, scale)

                # Convert to JPG if needed
                if img_format == "jpg":
                    filepath = self.image_processor.convert_to_jpg(filepath)

                if img_format != "apng":
                    saved_paths.append(str(filepath))
                    logger.debug(f"Captured: {filepath}")
                
                # Capture HTML or selector if requested
                # Always get selector
                selector = await self.get_visible_selector(page)
                
                if html:
                    visible_html = await self.get_visible_html(page)
                    # Store both selector and HTML when in html mode
                    html_data[str(filepath)] = {
                        "selector": selector,
                        "html": visible_html
                    }
                else:
                    html_data[str(filepath)] = selector

            except Exception as e:
                logger.error(
                    f"Failed to capture screenshot at position {scroll_pos}: {e}"
                )
                continue  # Continue with next screenshot

        # Create APNG if requested
        if img_format == "apng" and temp_png_paths:
            try:
                apng_path = self.image_processor.create_apng(
                    temp_png_paths, domain, output_path, anim_spf
                )
                saved_paths.append(str(apng_path))
                logger.info(f"Created APNG: {apng_path}")

                # Clean up temporary PNG files
                for temp_path in temp_png_paths:
                    try:
                        temp_path.unlink()
                    except Exception as e:
                        logger.warning(f"Failed to delete temp file {temp_path}: {e}")
            except Exception as e:
                logger.error(f"Failed to create APNG: {e}")

        return saved_paths, html_data

    async def get_section_id(self, page) -> str:
        """Get a smart ID based on current visible content.

        This method attempts to identify the current section by looking
        for visible headers or elements with IDs in the viewport.

        Args:
            page: Playwright page instance

        Returns:
            Section identifier string

        """
        try:
            # Execute JavaScript to find visible headers in viewport
            headers = await page.evaluate("""() => {
                const viewportHeight = window.innerHeight;
                const headers = Array.from(
                    document.querySelectorAll('h1, h2, h3, h4, h5, h6, [id]')
                );
                
                for (const header of headers) {
                    const rect = header.getBoundingClientRect();
                    if (rect.top >= 0 && rect.top < viewportHeight / 2) {
                        return (header.id || header.textContent || '').trim()
                            .toLowerCase()
                            .replace(/[^a-z0-9]+/g, '-')
                            .replace(/^-+|-+$/g, '')
                            .substring(0, 20);
                    }
                }
                return 'section';
            }""")

            return headers or "section"
        except Exception:
            return "section"
    
    async def get_visible_html(self, page) -> str:
        """Get minified HTML of visible portion of the page.
        
        Args:
            page: Playwright page instance
        
        Returns:
            Minified HTML string of visible elements

        """
        try:
            visible_html = await page.evaluate("""() => {
                const {innerHeight: H, innerWidth: W} = window;
                const nodes = [...document.querySelectorAll('*')];
                const fullyVisibleElements = [];
                
                // Tags to exclude from capture
                const excludeTags = ['HTML', 'HEAD', 'BODY', 'SCRIPT', 'STYLE', 'META', 'LINK', 'TITLE'];
                
                // Find elements that are FULLY visible in the viewport
                nodes.forEach(node => {
                    // Skip excluded tags and non-element nodes
                    if (excludeTags.includes(node.tagName) || node.nodeType !== 1) {
                        return;
                    }
                    
                    const r = node.getBoundingClientRect();
                    // Check if element is fully visible
                    if (r.top >= 0 && r.bottom <= H && r.left >= 0 && r.right <= W && r.width > 0 && r.height > 0) {
                        // Check if this element is already contained in a parent we've added
                        let isContained = false;
                        for (const existing of fullyVisibleElements) {
                            if (existing.contains(node)) {
                                isContained = true;
                                break;
                            }
                        }
                        if (!isContained) {
                            // Remove any previously added children of this element
                            const filtered = fullyVisibleElements.filter(el => !node.contains(el));
                            fullyVisibleElements.length = 0;
                            fullyVisibleElements.push(...filtered, node);
                        }
                    }
                });
                
                // Convert to HTML strings and concatenate
                const htmlParts = fullyVisibleElements.map(el => el.outerHTML);
                
                // Return minified HTML
                return htmlParts.join('').replace(/\\s+/g, ' ').trim();
            }""")
            return visible_html
        except Exception as e:
            logger.error(f"Failed to get visible HTML: {e}")
            return ""
    
    async def get_visible_selector(self, page) -> str:
        """Get a good selector for the visible portion of the page.
        
        Args:
            page: Playwright page instance
        
        Returns:
            CSS selector string for visible portion

        """
        try:
            selector = await page.evaluate("""() => {
                const {innerHeight: H} = window;
                
                // Try to find the most specific container for visible content
                const candidates = [
                    'main', 'article', '[role="main"]', '.content', '#content',
                    'section:first-of-type', 'div.container'
                ];
                
                for (const sel of candidates) {
                    const el = document.querySelector(sel);
                    if (el) {
                        const r = el.getBoundingClientRect();
                        if (r.top < H && r.bottom > 0) {
                            return sel;
                        }
                    }
                }
                
                // Find first visible section or div
                const sections = [...document.querySelectorAll('section, div')];
                for (const section of sections) {
                    const r = section.getBoundingClientRect();
                    if (r.top >= 0 && r.top < H/2) {
                        if (section.id) return '#' + section.id;
                        if (section.className) {
                            const classes = section.className.split(' ').filter(c => c);
                            if (classes.length) return '.' + classes.join('.');
                        }
                    }
                }
                
                // Fallback to body viewport
                return 'body';
            }""")
            return selector
        except Exception as e:
            logger.error(f"Failed to get visible selector: {e}")
            return "body"
</file>

<file path="src/brosh/cli.py">
#!/usr/bin/env python3
# this_file: src/brosh/cli.py

"""CLI interface for brosh."""

import asyncio
import platform
import subprocess
import time
from typing import Dict, List, Union

import platformdirs
from loguru import logger

from .browser import BrowserManager
from .tool import BrowserScreenshotTool


class BrowserScreenshotCLI:
    """Fire CLI interface for browser screenshot operations.

    Provides organized commands for browser management and screenshot capture.

    """

    def __init__(
        self,
        app: str = "",
        width: int = 0,
        height: int = 0,
        zoom: int = 100,
        output_dir: str = platformdirs.user_pictures_dir(),
        subdirs: bool = False,
        verbose: bool = False,
    ) -> None:
        """Initialize CLI with common parameters.

        Args:
            app: Browser to use - chrome, edge, safari (default: auto-detect)
            width: Width in pixels (default: screen width)
            height: Height in pixels (-1: no limit, default: screen height)
            zoom: Zoom level in % (default: 100)
            output_dir: Output folder for screenshots (default: user's pictures)
            subdirs: Create subfolders per domain
            verbose: Enable debug logging

        """
        self.app = app
        self.width = width
        self.height = height
        self.zoom = zoom
        self.output_dir = output_dir
        self.subdirs = subdirs
        self.verbose = verbose
        self._tool = BrowserScreenshotTool(verbose=verbose)
        self._browser_manager = BrowserManager()

    def run(self, force_run: bool = False) -> str:
        """Run browser in remote debug mode.

        Args:
            force_run: Always restart browser even if already running

        Returns:
            Status message

        """
        browser_name = self._browser_manager.get_browser_name(self.app)
        debug_ports = self._browser_manager.debug_ports
        debug_port = debug_ports.get(browser_name, 9222)

        # Check if already running
        if not force_run:
            try:
                import urllib.request

                urllib.request.urlopen(f"http://localhost:{debug_port}/json", timeout=2)
                return f"{browser_name} already running on port {debug_port}"
            except Exception:
                pass

        # Kill existing processes first if force_run
        if force_run:
            self.quit()
            time.sleep(2)

        # Launch browser directly with debug args
        browser_path = self._browser_manager.find_browser_path(browser_name)
        if not browser_path:
            return f"Could not find {browser_name} installation"

        try:
            width = self.width or 1440
            height = self.height or 900

            args = [browser_path] + self._browser_manager.get_browser_args(
                browser_name, width, height, debug_port
            )

            if not args[1:]:  # No args returned (not chromium/msedge)
                return f"Browser {browser_name} not supported for direct launch"

            logger.info(f"Starting {browser_name} with debug port {debug_port}")
            subprocess.Popen(args, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

            # Wait and verify connection
            for attempt in range(10):
                time.sleep(1)
                try:
                    import urllib.request

                    urllib.request.urlopen(
                        f"http://localhost:{debug_port}/json", timeout=2
                    )
                    return f"Started {browser_name} in debug mode on port {debug_port}"
                except Exception:
                    continue

            return f"Started {browser_name} but could not verify debug connection"

        except Exception as e:
            return f"Failed to start {browser_name}: {e}"

    def quit(self) -> str:
        """Quit the specified browser.

        Returns:
            Status message

        """
        browser_name = self._browser_manager.get_browser_name(self.app)
        debug_ports = self._browser_manager.debug_ports
        debug_port = debug_ports.get(browser_name, 9222)

        try:
            if platform.system() == "Darwin":  # macOS
                subprocess.run(
                    ["pkill", "-f", f"remote-debugging-port={debug_port}"],
                    capture_output=True,
                    timeout=5,
                )
                if "chrome" in browser_name.lower():
                    subprocess.run(
                        ["pkill", "-f", "Google Chrome.*remote-debugging"],
                        capture_output=True,
                        timeout=5,
                    )
            else:  # Windows/Linux
                subprocess.run(
                    ["taskkill", "/F", "/IM", "chrome.exe"],
                    capture_output=True,
                    timeout=5,
                )

            return f"Quit {browser_name}"
        except Exception as e:
            return f"Failed to quit {browser_name}: {e}"

    def shot(
        self,
        url: str,
        scroll_step: int = 100,
        scale: int = 100,
        format: str = "png",
        anim_spf: float = 0.5,
        html: bool = False,
        max_frames: int = 0,
        json: bool = False,
        from_selector: str = "",
    ) -> list[str] | dict[str, str] | str:
        """Take screenshots of a webpage.

        Automatically ensures browser is running in debug mode.

        Args:
            url: The URL to navigate to (mandatory)
            scroll_step: Scroll step in % of height (default: 100)
            scale: Scale in % for resampling output image (default: 100)
            format: Output format - png, jpg, or apng (default: png)
            anim_spf: Seconds per frame for APNG animation (default: 0.5)
            html: Return dict with HTML/selectors instead of list (default: False)
            max_frames: Maximum number of frames to capture, 0 for all (default: 0)
            json: Return JSON string output (default: False)
            from_selector: CSS selector to scroll to before starting capture (default: "")

        Returns:
            If json=True: JSON string of the results
            If html=True: Dict with screenshot paths as keys and HTML/selectors as values
            If html=False: List of paths to saved screenshot files

        """
        # Ensure browser is running in debug mode
        self.run(force_run=False)

        result = asyncio.run(
            self._tool.capture(
                url=url,
                zoom=self.zoom,
                width=self.width,
                height=self.height,
                scroll_step=scroll_step,
                scale=scale,
                app=self.app,
                output_dir=self.output_dir,
                subdirs=self.subdirs,
                mcp=False,
                format=format,
                anim_spf=anim_spf,
                html=html,
                max_frames=max_frames,
                from_selector=from_selector,
            )
        )

        if json:
            import json as json_module

            return json_module.dumps(result, indent=2)
        return result

    def mcp(self) -> None:
        """Run MCP server for browser screenshots.

        Automatically ensures browser is running in debug mode.

        """
        # Ensure browser is running in debug mode
        self.run(force_run=False)

        # Import and run MCP server
        from .mcp import run_mcp_server

        run_mcp_server()
</file>

<file path="src/brosh/image.py">
#!/usr/bin/env python3
# this_file: src/brosh/image.py

"""Image processing utilities for brosh."""

from pathlib import Path
from typing import List

from PIL import Image
from loguru import logger


class ImageProcessor:
    """Handles image processing operations."""

    @staticmethod
    def scale_image(filepath: Path, scale: int) -> None:
        """Scale the image by the given percentage.

        Args:
            filepath: Path to the image file
            scale: Scale percentage (100 = no scaling)

        """
        try:
            img = Image.open(filepath)
            new_width = int(img.width * scale / 100)
            new_height = int(img.height * scale / 100)
            resized = img.resize((new_width, new_height), Image.Resampling.LANCZOS)
            resized.save(filepath)
        except Exception as e:
            logger.error(f"Failed to scale image {filepath}: {e}")

    @staticmethod
    def convert_to_jpg(png_path: Path) -> Path:
        """Convert PNG to JPG format.

        Args:
            png_path: Path to PNG file

        Returns:
            Path to JPG file

        """
        try:
            jpg_path = png_path.with_suffix(".jpg")
            img = Image.open(png_path)

            # Convert RGBA to RGB for JPG
            if img.mode in ("RGBA", "LA", "P"):
                background = Image.new("RGB", img.size, (255, 255, 255))
                if img.mode == "P":
                    img = img.convert("RGBA")
                background.paste(
                    img, mask=img.split()[-1] if img.mode == "RGBA" else None
                )
                img = background

            img.save(jpg_path, "JPEG", quality=90)
            png_path.unlink()  # Remove original PNG
            return jpg_path
        except Exception as e:
            logger.error(f"Failed to convert {png_path} to JPG: {e}")
            return png_path  # Return original if conversion fails

    @staticmethod
    def create_apng(
        png_paths: list[Path],
        domain: str,
        output_path: Path,
        anim_spf: float,
    ) -> Path:
        """Create an animated PNG from a list of PNG files.

        Args:
            png_paths: List of PNG file paths to combine
            domain: Domain name for output filename
            output_path: Output directory
            anim_spf: Seconds per frame

        Returns:
            Path to created APNG file

        """
        apng_path = output_path / f"{domain}-animated.png"

        try:
            # Load all images
            images = []
            for png_path in png_paths:
                img = Image.open(png_path)
                images.append(img)

            # Convert seconds per frame to milliseconds
            duration_ms = int(anim_spf * 1000)

            # Save as animated PNG
            if images:
                images[0].save(
                    apng_path,
                    format="PNG",
                    save_all=True,
                    append_images=images[1:],
                    duration=duration_ms,
                    loop=0,  # Infinite loop
                )
        except Exception as e:
            logger.error(f"Failed to create APNG: {e}")
            raise

        return apng_path
</file>

<file path="src/brosh/mcp.py">
#!/usr/bin/env python3
# this_file: src/brosh/mcp.py

"""MCP server implementation for brosh."""

import sys
from typing import Dict, Union

import platformdirs

try:
    from fastmcp import FastMCP, Image
except ImportError:
    print("FastMCP not installed. Please install it with: pip install fastmcp")
    sys.exit(1)

from loguru import logger

from .tool import BrowserScreenshotTool


def run_mcp_server():
    """Run the FastMCP server for browser screenshots."""
    
    mcp = FastMCP(
        name="Browser Screenshots",
        instructions=(
            "This _tool captures sequential screenshots of a webpage "
            "by scrolling through it in a real browser. "
            "You can specify URL, zoom, viewport size, scroll step, "
            "output scaling, format (png/jpg/apng), and animation "
            "speed. Screenshots are saved with descriptive filenames "
            "including domain, scroll position, and smart section "
            "identifiers. Choose browser or use OS default. If "
            "subdirs enabled, screenshots organized by domain. "
            "Ideal for long pages, documentation, QA. Works with "
            "remote debugging mode preserving authentication and "
            "cookies."
        ),
    )

    @mcp.tool
    async def capture_screenshot(
        url: str,
        zoom: int = 100,
        width: int = 0,
        height: int = 0,
        scroll_step: int = 100,
        scale: int = 100,
        app: str = "",
        output_dir: str = platformdirs.user_pictures_dir(),
        subdirs: bool = False,
        format: str = "png",
        anim_spf: float = 0.5,
        html: bool = False,
        max_frames: int = 0,
        from_selector: str = "",
    ) -> dict[str, dict[str, str | Image]]:
        """Capture screenshots of a webpage using Playwright.

        Args:
            url: The URL to navigate to (mandatory)
            zoom: Zoom level in % (default: 100)
            width: Width in pixels (default: main screen width)
            height: Height in pixels (default: main screen height). Use -1 to capture entire page
            scroll_step: Scroll step in % of height (default: 100)
            scale: Scale in % for resampling output image
                   (default: 100)
            app: Browser to use (default: OS default browser)
            output_dir: Output directory for screenshots
                       (default: Pictures)
            subdirs: Create subdirectories for domains
                    (default: False)
            format: Output format - png, jpg, or apng (default: png)
            anim_spf: Seconds per frame for APNG animation
                     (default: 0.5)
            html: Return dict with HTML/selectors instead of list
                 (default: False)
            max_frames: Maximum number of frames to capture, 0 for all
                       (default: 0)
            from_selector: CSS selector to scroll to before starting capture
                          (default: "")

        Returns:
            Dict with screenshot paths as keys and values containing:
            - "image": FastMCP Image object with the screenshot
            - "selector": CSS selector for the visible portion
            - "html": (optional, if html=True) HTML of visible elements
        """
        # Create a new instance to avoid recursion
        tool = BrowserScreenshotTool()
        
        # Capture with both selectors and optionally HTML
        result = await tool.capture(
            url=url,
            zoom=zoom,
            width=width,
            height=height,
            scroll_step=scroll_step,
            scale=scale,
            app=app,
            output_dir=output_dir,
            subdirs=subdirs,
            mcp=False,  # Never recurse into MCP mode
            format=format,
            anim_spf=anim_spf,
            html=html,  # This will get both selector and HTML if True
            max_frames=max_frames,
            from_selector=from_selector,
        )
        
        # For MCP mode, we need to return a dict with image data
        if isinstance(result, dict):
            # Result is already a dict with paths as keys
            mcp_result = {}
            for path, value in result.items():
                # Read the image file
                try:
                    with open(path, "rb") as f:
                        img_bytes = f.read()
                    
                    # Determine format from path
                    path_lower = path.lower()
                    if path_lower.endswith('.png'):
                        img_format = "png"
                    elif path_lower.endswith(('.jpg', '.jpeg')):
                        img_format = "jpeg"
                    else:
                        img_format = "png"
                    
                    # Build the response dict
                    response_dict = {
                        "image": Image(data=img_bytes, format=img_format),
                    }
                    
                    # Handle both old format (string selector) and new format (dict with selector and html)
                    if isinstance(value, dict):
                        response_dict["selector"] = value.get("selector", "body")
                        if "html" in value:
                            response_dict["html"] = value["html"]
                    else:
                        # Old format - value is just the selector
                        response_dict["selector"] = value
                    
                    mcp_result[path] = response_dict
                    
                except Exception as e:
                    logger.error(f"Failed to read image {path}: {e}")
                    continue
            
            return mcp_result
        else:
            # Result is a list of paths (shouldn't happen with current logic)
            # Convert to dict format expected by MCP
            mcp_result = {}
            for path in result:
                try:
                    with open(path, "rb") as f:
                        img_bytes = f.read()
                    
                    # Determine format from path
                    path_lower = path.lower()
                    if path_lower.endswith('.png'):
                        img_format = "png"
                    elif path_lower.endswith(('.jpg', '.jpeg')):
                        img_format = "jpeg"
                    else:
                        img_format = "png"
                    
                    mcp_result[path] = {
                        "image": Image(data=img_bytes, format=img_format),
                        "selector": "body",  # Default selector
                    }
                except Exception as e:
                    logger.error(f"Failed to read image {path}: {e}")
                    continue
            
            return mcp_result

    mcp.run()


def main():
    """Entry point for the brosh-mcp command."""
    run_mcp_server()


if __name__ == "__main__":
    main()
</file>

<file path="src/brosh/models.py">
#!/usr/bin/env python3
# this_file: src/brosh/models.py

"""Data models and enums for the brosh package."""

from enum import Enum


class ImageFormat(str, Enum):
    """Supported image output formats."""

    PNG = "png"
    JPG = "jpg"
    APNG = "apng"
</file>

<file path="src/brosh/tool.py">
#!/usr/bin/env python3
# this_file: src/brosh/_tool.py

"""Main screenshot _tool implementation for brosh."""

import asyncio
import sys
from pathlib import Path
from typing import Dict, List, Union
from urllib.parse import urlparse

import platformdirs
from loguru import logger
from playwright.async_api import async_playwright

from .browser import BrowserManager
from .capture import CaptureManager
from .image import ImageProcessor
from .models import ImageFormat


class BrowserScreenshotTool:
    """Tool for capturing scrolling screenshots using Playwright async API.

    Optimized for reliability with comprehensive error handling,
    intelligent browser detection, and performance optimizations.

    """

    def __init__(self, verbose: bool = False):
        """Initialize the screenshot _tool with default settings.
        
        Args:
            verbose: Enable debug logging

        """
        self.max_retries = 3
        self.connection_timeout = 30
        self.page_timeout = 60
        self.screenshot_timeout = 10
        self.verbose = verbose
        
        # Configure logging based on verbose flag
        if not verbose:
            logger.remove()
            logger.add(sys.stderr, level="ERROR")
        
        # Initialize managers
        self.browser_manager = BrowserManager(self.connection_timeout)
        self.capture_manager = CaptureManager(self.page_timeout, self.screenshot_timeout)
        self.image_processor = ImageProcessor()

    async def capture(
        self,
        url: str,
        zoom: int = 100,
        width: int = 0,
        height: int = 0,
        scroll_step: int = 100,
        scale: int = 100,
        app: str = "",
        output_dir: str = platformdirs.user_pictures_dir(),
        subdirs: bool = False,
        mcp: bool = False,
        format: str = "png",
        anim_spf: float = 0.5,
        html: bool = False,
        max_frames: int = 0,
        from_selector: str = "",
    ) -> list[str] | dict[str, str]:
        """Capture screenshots of a webpage using Playwright.

        This method navigates to a URL and captures sequential screenshots
        while scrolling through the page. Each screenshot is named with
        domain, scroll position, and section identifier.

        Args:
            url: The URL to navigate to (mandatory)
            zoom: Zoom level in % (default: 100)
            width: Width in pixels (default: main screen width)
            height: Height in pixels (default: main screen height). Use -1 to capture entire page
            scroll_step: Scroll step in % of height (default: 100)
            scale: Scale in % for resampling output image (default: 100)
            app: Browser to use - chrome, edge, safari (default: auto-detect)
            output_dir: Output directory for screenshots (default: Pictures)
            subdirs: Create subdirectories for domains (default: False)
            mcp: Run in FastMCP mode (default: False)
            format: Output format - png, jpg, or apng (default: png)
            anim_spf: Seconds per frame for APNG animation (default: 0.5)
            html: Return dict with HTML/selectors instead of list
                 (default: False)
            max_frames: Maximum number of frames to capture, 0 for all
                       (default: 0)
            from_selector: CSS selector to scroll to before starting capture
                          (default: "")

        Returns:
            If html=True: Dict with screenshot paths as keys and HTML/selectors
                         as values
            If html=False: List of paths to saved screenshot files

        Raises:
            ValueError: For invalid parameters
            RuntimeError: For browser connection or navigation failures

        """
        if mcp:
            # This should be handled in mcp.py now
            raise RuntimeError("MCP mode should be handled by mcp module")

        # Validate inputs
        self.capture_manager.validate_inputs(url, zoom, scroll_step, scale, format)
        img_format = format.lower()

        # Parse URL and get domain for filename generation
        parsed_url = urlparse(url)
        domain = parsed_url.netloc.replace("www.", "").replace(".", "_")
        if not domain:
            raise ValueError(f"Invalid URL: {url}")

        # Create output directory structure
        output_path = Path(output_dir)
        if subdirs:
            output_path = output_path / domain
        output_path.mkdir(parents=True, exist_ok=True)

        # Get screen dimensions if not specified
        if width == 0 or (height == 0 or height == -1):
            default_width, default_height = self.browser_manager.get_screen_dimensions()
            width = width or default_width
            if height == 0:
                height = default_height
            # If height is -1, we'll handle it as "capture entire page"

        if height == -1:
            logger.info(f"Starting capture of {url} at {width}x(entire page)")
        else:
            logger.info(f"Starting capture of {url} at {width}x{height}")

        # Determine browser to use (no Firefox support)
        browser_name = self.browser_manager.get_browser_name(app)
        logger.info(f"Using browser: {browser_name}")

        saved_paths = []
        html_data = {}  # For HTML/selector data when html=True
        temp_png_paths: list[Path] = []  # For APNG conversion

        # Retry mechanism for browser connection
        for attempt in range(self.max_retries):
            try:
                async with async_playwright() as p:
                    # Connect to existing browser or launch new one
                    browser, context, page = await self.browser_manager.get_browser_instance(
                        p, browser_name, width, height, zoom
                    )

                    try:
                        saved_paths, html_data = await self.capture_manager.capture_screenshots(
                            page,
                            url,
                            domain,
                            output_path,
                            width,
                            height,
                            scroll_step,
                            scale,
                            img_format,
                            anim_spf,
                            temp_png_paths,
                            html,
                            max_frames,
                            from_selector,
                        )
                        logger.info(
                            f"Successfully captured {len(saved_paths)} screenshots"
                        )
                        break  # Success, exit retry loop

                    finally:
                        # Clean up browser resources
                        await self.browser_manager.cleanup_browser(page, context, browser)

            except Exception as e:
                logger.error(f"Attempt {attempt + 1}/{self.max_retries} failed: {e}")
                if attempt == self.max_retries - 1:
                    raise RuntimeError(
                        f"Failed to capture screenshots after "
                        f"{self.max_retries} attempts: {e}"
                    )
                await asyncio.sleep(2)  # Wait before retry

        # Always return html_data when populated (either HTML content or selectors)
        if html_data:
            return html_data
        return saved_paths
</file>

<file path=".cursorindexingignore">
# Don't index SpecStory auto-save files, but allow explicit context inclusion via @ references
.specstory/**
</file>

<file path="CHANGELOG.md">
# Refactoring Summary

## What Was Done

The monolithic `_private/brosh.py` file (1559 lines) has been successfully refactored into a modular Python package structure.

### Module Structure Created

```
src/brosh/
 __init__.py      # Package exports
 __main__.py      # CLI entry point
 cli.py           # BrowserScreenshotCLI class (219 lines)
 tool.py          # BrowserScreenshotTool class (165 lines)
 browser.py       # BrowserManager class (436 lines)
 capture.py       # CaptureManager class (395 lines)
 image.py         # ImageProcessor class (88 lines)
 models.py        # ImageFormat enum (14 lines)
 mcp.py           # MCP server functionality (194 lines)
```

### Key Changes

1. **Separation of Concerns**: Each module now has a specific responsibility
   - Browser management separated from capture logic
   - Image processing isolated in its own module
   - MCP server functionality extracted

2. **Backward Compatibility**: All functionality preserved
   - Same CLI commands work as before
   - All parameters and options maintained
   - Output format remains identical

3. **Package Configuration**: Updated `pyproject.toml` with:
   - Two CLI entry points: `brosh` and `brosh-mcp`
   - Proper dependencies with relaxed version constraints
   - Modern Python packaging standards

4. **Documentation Updates**:
   - README.md: Complete usage guide and examples
   - CLAUDE.md: Updated with new architecture
   - PLAN.md: Detailed refactoring plan

### Benefits

1. **Maintainability**: Code is now modular and easier to understand
2. **Testability**: Each module can be tested independently
3. **Extensibility**: New features can be added to specific modules
4. **Reusability**: Components can be imported and used separately

### Installation & Usage

```bash
# Install in development mode
pip install -e .

# Test the CLI
brosh --help
brosh shot "https://example.com"

# Run MCP server
brosh-mcp
```

All original functionality has been preserved while improving code organization and maintainability.
</file>

<file path="cleanup.sh">
#!/usr/bin/env bash

python -m uzpy run -e src
fd -e py -x autoflake {}
fd -e py -x pyupgrade --py311-plus {}
fd -e py -x ruff check --output-format=github --fix --unsafe-fixes {}
fd -e py -x ruff format --respect-gitignore --target-version py311 {}
repomix -i varia,.specstory,AGENT.md,CLAUDE.md,PLAN.md,SPEC.md,llms.txt,.cursorrules -o llms.txt .
python -m pytest

rm -rf dist/brosh*.*
uv build
</file>

<file path="pyrightconfig.json">
{
  "include": [
    "**/*.py"
  ],
  "exclude": [
    "src",
    "**/node_modules",
    "**/__pycache__"
  ],
  "reportMissingImports": false,
  "reportMissingTypeStubs": false,
  "pythonVersion": "3.10"
}
</file>

<file path="TODO.md">
# TODO

```
brosh|cat

NAME
    brosh - Fire CLI interface for browser screenshot operations.

SYNOPSIS
    brosh - GROUP | COMMAND | VALUE

DESCRIPTION
    Provides organized commands for browser management and screenshot capture.

GROUPS
    GROUP is one of the following:

     browser_manager
       Manages browser detection, launching, and connection.

     tool
       Tool for capturing scrolling screenshots using Playwright async API.

COMMANDS
    COMMAND is one of the following:

     mcp
       Run MCP server for browser screenshots.

     quit
       Quit the specified browser.

     run
       Run browser in remote debug mode.

     shot
       Take screenshots of a webpage.

VALUES
    VALUE is one of the following:

     app
       Browser to use - chrome, edge, safari (default: auto-detect)

     height
       Height in pixels (default: main screen height)

     output_dir
       Output directory for screenshots (default: Pictures)

     subdirs
       Create subdirectories for domains (default: False)

     verbose
       Enable debug logging (default: False)

     width
       Width in pixels (default: main screen width)

     zoom
       Zoom level in % (default: 100)
```

```
brosh-mcp
[06/12/25 18:57:14] INFO     Starting MCP server 'Browser Screenshots' with transport 'stdio'                  server.py:1159
```

- [ ] Run ./cleanup.sh and analyze the results. Use them to add new TODOs into this file. 
- [ ] Run the code checks and 
- [ ] Start implementing the TODOs. 
- [ ] Repeat the above steps until the TODO list is reasonably empty. 
- [ ] Rewrite CHANGELOG.md to a sensible format (today is 2025 June 12). 
- [ ] Update README.md. Research 'uvx' instalation of MCP servers, write a very very extensive documentation for our tool (both the CLI and MCP). Describe how the tool works, and why it's useful.
</file>

<file path=".github/workflows/push.yml">
name: Build & Test

on:
  push:
    branches: [main]
    tags-ignore: ["v*"]
  pull_request:
    branches: [main]
  workflow_dispatch:

permissions:
  contents: write
  id-token: write

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  quality:
    name: Code Quality
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Run Ruff lint
        uses: astral-sh/ruff-action@v3
        with:
          version: "latest"
          args: "check --output-format=github"

      - name: Run Ruff Format
        uses: astral-sh/ruff-action@v3
        with:
          version: "latest"
          args: "format --check --respect-gitignore"

  test:
    name: Run Tests
    needs: quality
    strategy:
      matrix:
        python-version: ["3.10", "3.11", "3.12"]
        os: [ubuntu-latest]
      fail-fast: true
    runs-on: ${{ matrix.os }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install UV
        uses: astral-sh/setup-uv@v5
        with:
          version: "latest"
          python-version: ${{ matrix.python-version }}
          enable-cache: true
          cache-suffix: ${{ matrix.os }}-${{ matrix.python-version }}

      - name: Install test dependencies
        run: |
          uv pip install --system --upgrade pip
          uv pip install --system ".[test]"

      - name: Run tests with Pytest
        run: uv run pytest -n auto --maxfail=1 --disable-warnings --cov-report=xml --cov-config=pyproject.toml --cov=src/brosh --cov=tests tests/

      - name: Upload coverage report
        uses: actions/upload-artifact@v4
        with:
          name: coverage-${{ matrix.python-version }}-${{ matrix.os }}
          path: coverage.xml

  build:
    name: Build Distribution
    needs: test
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install UV
        uses: astral-sh/setup-uv@v5
        with:
          version: "latest"
          python-version: "3.12"
          enable-cache: true

      - name: Install build tools
        run: uv pip install build hatchling hatch-vcs

      - name: Build distributions
        run: uv run python -m build --outdir dist

      - name: Upload distribution artifacts
        uses: actions/upload-artifact@v4
        with:
          name: dist-files
          path: dist/
          retention-days: 5
</file>

<file path=".github/workflows/release.yml">
name: Release

on:
  push:
    tags: ["v*"]

permissions:
  contents: write
  id-token: write

jobs:
  release:
    name: Release to PyPI
    runs-on: ubuntu-latest
    environment:
      name: pypi
      url: https://pypi.org/p/brosh
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install UV
        uses: astral-sh/setup-uv@v5
        with:
          version: "latest"
          python-version: "3.12"
          enable-cache: true

      - name: Install build tools
        run: uv pip install build hatchling hatch-vcs

      - name: Build distributions
        run: uv run python -m build --outdir dist

      - name: Verify distribution files
        run: |
          ls -la dist/
          test -n "$(find dist -name '*.whl')" || (echo "Wheel file missing" && exit 1)
          test -n "$(find dist -name '*.tar.gz')" || (echo "Source distribution missing" && exit 1)

      - name: Publish to PyPI
        uses: pypa/gh-action-pypi-publish@release/v1
        with:
          password: ${{ secrets.PYPI_TOKEN }}

      - name: Create GitHub Release
        uses: softprops/action-gh-release@v1
        with:
          files: dist/*
          generate_release_notes: true
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
</file>

<file path="src/brosh/brosh.py">
#!/usr/bin/env python3
"""brosh: 

Created by Adam Twardoch
"""

from dataclasses import dataclass
from pathlib import Path
from typing import Any, Dict, List, Optional, Union
import logging

__version__ = "0.1.0"

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


@dataclass
class Config:
    """Configuration settings for brosh."""
    name: str
    value: str | int | float
    options: dict[str, Any] | None = None


def process_data(
    data: list[Any],
    config: Config | None = None,
    *,
    debug: bool = False
) -> dict[str, Any]:
    """Process the input data according to configuration.
    
    Args:
        data: Input data to process
        config: Optional configuration settings
        debug: Enable debug mode
        
    Returns:
        Processed data as a dictionary
        
    Raises:
        ValueError: If input data is invalid
    """
    if debug:
        logger.setLevel(logging.DEBUG)
        logger.debug("Debug mode enabled")
        
    if not data:
        raise ValueError("Input data cannot be empty")
        
    # TODO: Implement data processing logic
    result: dict[str, Any] = {}
    return result


def main() -> None:
    """Main entry point for brosh."""
    try:
        # Example usage
        config = Config(
            name="default",
            value="test",
            options={"key": "value"}
        )
        result = process_data([], config=config)
        logger.info("Processing completed: %s", result)
        
    except Exception as e:
        logger.error("An error occurred: %s", str(e))
        raise


if __name__ == "__main__":
    main()
</file>

<file path="tests/test_package.py">
"""Test suite for brosh."""

def test_version():
    """Verify package exposes version.

"""
    import brosh
    assert brosh.__version__
</file>

<file path=".gitignore">
*_autogen/
.DS_Store
__version__.py
__pycache__/
_Chutzpah*
_deps
_NCrunch_*
_pkginfo.txt
_Pvt_Extensions
_ReSharper*/
_TeamCity*
_UpgradeReport_Files/
!?*.[Cc]ache/
!.axoCover/settings.json
!.vscode/extensions.json
!.vscode/launch.json
!.vscode/settings.json
!.vscode/tasks.json
!**/[Pp]ackages/build/
!Directory.Build.rsp
.*crunch*.local.xml
.axoCover/*
.builds
.cr/personal
.fake/
.history/
.ionide/
.localhistory/
.mfractor/
.ntvs_analysis.dat
.paket/paket.exe
.sass-cache/
.vs/
.vscode
.vscode/*
.vshistory/
[Aa][Rr][Mm]/
[Aa][Rr][Mm]64/
[Bb]in/
[Bb]uild[Ll]og.*
[Dd]ebug/
[Dd]ebugPS/
[Dd]ebugPublic/
[Ee]xpress/
[Ll]og/
[Ll]ogs/
[Oo]bj/
[Rr]elease/
[Rr]eleasePS/
[Rr]eleases/
[Tt]est[Rr]esult*/
[Ww][Ii][Nn]32/
*_h.h
*_i.c
*_p.c
*_wpftmp.csproj
*- [Bb]ackup ([0-9]).rdl
*- [Bb]ackup ([0-9][0-9]).rdl
*- [Bb]ackup.rdl
*.[Cc]ache
*.[Pp]ublish.xml
*.[Rr]e[Ss]harper
*.a
*.app
*.appx
*.appxbundle
*.appxupload
*.aps
*.azurePubxml
*.bim_*.settings
*.bim.layout
*.binlog
*.btm.cs
*.btp.cs
*.build.csdef
*.cab
*.cachefile
*.code-workspace
*.coverage
*.coveragexml
*.d
*.dbmdl
*.dbproj.schemaview
*.dll
*.dotCover
*.DotSettings.user
*.dsp
*.dsw
*.dylib
*.e2e
*.exe
*.gch
*.GhostDoc.xml
*.gpState
*.ilk
*.iobj
*.ipdb
*.jfm
*.jmconfig
*.la
*.lai
*.ldf
*.lib
*.lo
*.log
*.mdf
*.meta
*.mm.*
*.mod
*.msi
*.msix
*.msm
*.msp
*.ncb
*.ndf
*.nuget.props
*.nuget.targets
*.nupkg
*.nvuser
*.o
*.obj
*.odx.cs
*.opendb
*.opensdf
*.opt
*.out
*.pch
*.pdb
*.pfx
*.pgc
*.pgd
*.pidb
*.plg
*.psess
*.publishproj
*.publishsettings
*.pubxml
*.pyc
*.rdl.data
*.rptproj.bak
*.rptproj.rsuser
*.rsp
*.rsuser
*.sap
*.sbr
*.scc
*.sdf
*.sln.docstates
*.sln.iml
*.slo
*.smod
*.snupkg
*.so
*.suo
*.svclog
*.tlb
*.tlh
*.tli
*.tlog
*.tmp
*.tmp_proj
*.tss
*.user
*.userosscache
*.userprefs
*.vbp
*.vbw
*.VC.db
*.VC.VC.opendb
*.VisualState.xml
*.vsp
*.vspscc
*.vspx
*.vssscc
*.xsd.cs
**/[Pp]ackages/*
**/*.DesktopClient/GeneratedArtifacts
**/*.DesktopClient/ModelManifest.xml
**/*.HTMLClient/GeneratedArtifacts
**/*.Server/GeneratedArtifacts
**/*.Server/ModelManifest.xml
*~
~$*
$tf/
AppPackages/
artifacts/
ASALocalRun/
AutoTest.Net/
Backup*/
BenchmarkDotNet.Artifacts/
bld/
BundleArtifacts/
ClientBin/
cmake_install.cmake
CMakeCache.txt
CMakeFiles
CMakeLists.txt.user
CMakeScripts
CMakeUserPresets.json
compile_commands.json
coverage*.info
coverage*.json
coverage*.xml
csx/
CTestTestfile.cmake
dlldata.c
DocProject/buildhelp/
DocProject/Help/*.hhc
DocProject/Help/*.hhk
DocProject/Help/*.hhp
DocProject/Help/*.HxC
DocProject/Help/*.HxT
DocProject/Help/html
DocProject/Help/Html2
ecf/
FakesAssemblies/
FodyWeavers.xsd
Generated_Code/
Generated\ Files/
healthchecksdb
install_manifest.txt
ipch/
Makefile
MigrationBackup/
mono_crash.*
nCrunchTemp_*
node_modules/
nunit-*.xml
OpenCover/
orleans.codegen.cs
Package.StoreAssociation.xml
paket-files/
project.fragment.lock.json
project.lock.json
publish/
PublishScripts/
rcf/
ScaffoldingReadMe.txt
ServiceFabricBackup/
StyleCopReport.xml
Testing
TestResult.xml
UpgradeLog*.htm
UpgradeLog*.XML
x64/
x86/
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# Distribution / packaging
!dist/.gitkeep

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.py,cover
.hypothesis/
.pytest_cache/
cover/
.ruff_cache/

# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# IDE
.idea/
.vscode/
*.swp
*.swo
*~

# OS
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db

# Project specific
__version__.py
_private
VERSION.txt
</file>

<file path=".pre-commit-config.yaml">
repos:
  - repo: https://github.com/astral-sh/ruff-pre-commit
    rev: v0.3.4
    hooks:
      - id: ruff
        args: [--fix]
      - id: ruff-format
        args: [--respect-gitignore]
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.5.0
    hooks:
      - id: trailing-whitespace
      - id: check-yaml
      - id: check-toml
      - id: check-added-large-files
      - id: debug-statements
      - id: check-case-conflict
      - id: mixed-line-ending
        args: [--fix=lf]
</file>

<file path="LICENSE">
MIT License

Copyright (c) 2025 Adam Twardoch

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
</file>

<file path="package.toml">
# Package configuration
[package]
include_cli = true        # Include CLI boilerplate
include_logging = true    # Include logging setup
use_pydantic = true      # Use Pydantic for data validation
use_rich = true          # Use Rich for terminal output

[features]
mkdocs = false           # Enable MkDocs documentation
vcs = true              # Initialize Git repository
github_actions = true   # Add GitHub Actions workflows
</file>

<file path="pyproject.toml">
# this_file: pyproject.toml
#==============================================================================
# BROSH PACKAGE CONFIGURATION
# This pyproject.toml defines the package metadata, dependencies, build system,
# and development environment for the brosh package.
#==============================================================================

#------------------------------------------------------------------------------
# PROJECT METADATA
# Core package information used by PyPI and package managers.
#------------------------------------------------------------------------------
[project]
name = 'brosh' # Package name on PyPI
description = 'Browser screenshot tool using Playwright async API' # Short description
readme = 'README.md' # Path to README file
requires-python = '>=3.10' # Minimum Python version
keywords = [
    'screenshot',
    'browser',
    'playwright',
    'web',
    'capture',
    'automation',
    'mcp',
] # Keywords for PyPI search
dynamic = ["version"] # Fields set dynamically at build time

# PyPI classifiers for package categorization
classifiers = [
    'Development Status :: 4 - Beta', # Package maturity level
    'Programming Language :: Python',
    'Programming Language :: Python :: 3.10',
    'Programming Language :: Python :: 3.11',
    'Programming Language :: Python :: 3.12',
    'Programming Language :: Python :: Implementation :: CPython',
    'Programming Language :: Python :: Implementation :: PyPy',
    'Operating System :: OS Independent',
    'License :: OSI Approved :: MIT License',
    'Intended Audience :: Developers',
]

dependencies = [
    'fire>=0.5.0',
    'playwright>=1.40.0',
    'pillow>=10.0.0',
    'fastmcp>=0.5.0',
    'platformdirs>=4.0.0',
    'loguru>=0.7.0',
]

# Author information
[[project.authors]]
name = 'Adam Twardoch'
email = 'adam+github@twardoch.com'

# License information
[project.license]
text = 'MIT'

# Project URLs
[project.urls]
Documentation = 'https://github.com/twardoch/brosh#readme'
Issues = 'https://github.com/twardoch/brosh/issues'
Source = 'https://github.com/twardoch/brosh'

#------------------------------------------------------------------------------
# OPTIONAL DEPENDENCIES
# Additional dependencies for optional features, development, and testing.
#------------------------------------------------------------------------------
[project.optional-dependencies]

# Development tools
dev = [
    'pre-commit>=4.1.0', # Pre-commit hook manager - Keep pre-commit as is, update if newer pre-commit version is required
    'ruff>=0.9.7', # Linting and formatting - Keep ruff as is, update if newer ruff version is required
    'mypy>=1.15.0', # Type checking - Keep mypy as is, update if newer mypy version is required
    'absolufy-imports>=0.3.1', # Convert relative imports to absolute - Keep absolufy-imports as is, update if newer absolufy-imports version is required
    'pyupgrade>=3.19.1', # Upgrade Python syntax - Keep pyupgrade as is, update if newer pyupgrade version is required
    'isort>=6.0.1', # Sort imports - Keep isort as is, update if newer isort version is required
    'uzpy>=1.0.0', 
]

# Testing tools and frameworks
test = [
    'pytest>=8.3.4', # Testing framework - Keep pytest as is, update if newer pytest version is required
    'pytest-cov>=6.0.0', # Coverage plugin for pytest - Keep pytest-cov as is, update if newer pytest-cov version is required
    'pytest-xdist>=3.6.1', # Parallel test execution - Keep pytest-xdist as is, update if newer pytest-xdist version is required
    'pytest-benchmark[histogram]>=5.1.0', # Benchmarking plugin - Keep pytest-benchmark as is, update if newer pytest-benchmark version is required
    'pytest-asyncio>=0.25.3', # Async test support - Keep pytest-asyncio as is, update if newer pytest-asyncio version is required
    'coverage[toml]>=7.6.12',
]

docs = [
    "sphinx>=7.2.6",
    "sphinx-rtd-theme>=2.0.0",
    "sphinx-autodoc-typehints>=2.0.0",
    "myst-parser>=3.0.0", # Markdown support in Sphinx
]

# All optional dependencies combined
all = [
]

#------------------------------------------------------------------------------
# COMMAND-LINE SCRIPTS
# Entry points for command-line executables installed with the package.
#------------------------------------------------------------------------------
[project.scripts]
brosh = "brosh.__main__:main"
brosh-mcp = "brosh.mcp:main"

#------------------------------------------------------------------------------
# BUILD SYSTEM CONFIGURATION
# Defines the tools required to build the package and the build backend.
#------------------------------------------------------------------------------
[build-system]
# Hatchling is a modern build backend for Python packaging
# hatch-vcs integrates with version control systems for versioning
requires = [
    'hatchling>=1.27.0', # Keep hatchling as is, update if newer hatchling version is required
    'hatch-vcs>=0.4.0', # Keep hatch-vcs as is, update if newer hatch-vcs version is required
]
build-backend = 'hatchling.build' # Specifies Hatchling as the build backend


#------------------------------------------------------------------------------
# HATCH BUILD CONFIGURATION
# Configures the build process, specifying which packages to include and
# how to handle versioning.
#------------------------------------------------------------------------------
[tool.hatch.build]
# Include package data files
include = [
    "src/brosh/py.typed", # For better type checking support
    "src/brosh/data/**/*", # Include data files if any

]
exclude = ["**/__pycache__", "**/.pytest_cache", "**/.mypy_cache"]

[tool.hatch.build.targets.wheel]
packages = ["src/brosh"]
reproducible = true


# Version control system hook configuration
# Automatically updates the version file from git tags
[tool.hatch.build.hooks.vcs]
version-file = "src/brosh/__version__.py"

# Version source configuration
[tool.hatch.version]
source = 'vcs' # Get version from git tags or other VCS info

# Metadata handling configuration
[tool.hatch.metadata]
allow-direct-references = true # Allow direct references in metadata (useful for local dependencies)


#------------------------------------------------------------------------------
# DEVELOPMENT ENVIRONMENTS

[tool.hatch.envs.default]
features = ['dev', 'test', 'all']
dependencies = [
]

# Commands available in the default environment
[tool.hatch.envs.default.scripts]
# Run tests with optional arguments
test = 'pytest {args:tests}'
# Run tests with coverage reporting
test-cov = "pytest --cov-report=term-missing --cov-config=pyproject.toml --cov=src/brosh --cov=tests {args:tests}"
# Run type checking
type-check = "mypy src/brosh tests"
# Run linting and formatting
lint = ["ruff check src/brosh tests", "ruff format --respect-gitignore src/brosh tests"]
# Format and fix style issues
fmt = ["ruff format --respect-gitignore src/brosh tests", "ruff check --fix src/brosh tests"]
fix = ["ruff check --fix --unsafe-fixes src/brosh tests", "ruff format --respect-gitignore src/brosh tests"]

# Matrix configuration to test across multiple Python versions

[[tool.hatch.envs.all.matrix]]
python = ["3.10", "3.11", "3.12"]

#------------------------------------------------------------------------------
# SPECIALIZED ENVIRONMENTS
# Additional environments for specific development tasks.
#------------------------------------------------------------------------------

# Dedicated environment for linting and code quality checks
[tool.hatch.envs.lint]
detached = true # Create a separate, isolated environment
features = ['dev'] # Use dev extras  dependencies 

# Linting environment commands
[tool.hatch.envs.lint.scripts]
# Type checking with automatic type installation
typing = "mypy --install-types --non-interactive {args:src/brosh tests}"
# Check style and format code
style = ["ruff check {args:.}", "ruff format --respect-gitignore {args:.}"]
# Format and fix style issues
fmt = ["ruff format --respect-gitignore {args:.}", "ruff check --fix {args:.}"]
fix = ["ruff check --fix --unsafe-fixes {args:.}", "ruff format --respect-gitignore {args:.}"]
# Run all ops
all = ["style", "typing", "fix"]

# Dedicated environment for testing
[tool.hatch.envs.test]
features = ['test'] # Use test extras as dependencies

# Testing environment commands
[tool.hatch.envs.test.scripts]
# Run tests in parallel
test = "python -m pytest -n auto {args:tests}"
# Run tests with coverage in parallel
test-cov = "python -m pytest -n auto --cov-report=term-missing --cov-config=pyproject.toml --cov=src/brosh --cov=tests {args:tests}"
# Run benchmarks
bench = "python -m pytest -v -p no:briefcase tests/test_benchmark.py --benchmark-only"
# Run benchmarks and save results
bench-save = "python -m pytest -v -p no:briefcase tests/test_benchmark.py --benchmark-only --benchmark-json=benchmark/results.json"

# Documentation environment
[tool.hatch.envs.docs]
features = ['docs']

# Documentation environment commands
[tool.hatch.envs.docs.scripts]
build = "sphinx-build -b html docs/source docs/build"

# GitHub Actions workflow configuration
[tool.hatch.envs.ci]
features = ['test']


[tool.hatch.envs.ci.scripts]
test = "pytest --cov=src/brosh --cov-report=xml"


#------------------------------------------------------------------------------
# CODE QUALITY TOOLS
# Configuration for linting, formatting, and code quality enforcement.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# COVERAGE CONFIGURATION
# Settings for test coverage measurement and reporting.
#------------------------------------------------------------------------------

# Path mapping for coverage in different environments
[tool.coverage.paths]
brosh = ["src/brosh", "*/brosh/src/brosh"]
tests = ["tests", "*/brosh/tests"]

# Coverage report configuration
[tool.coverage.report]
# Lines to exclude from coverage reporting
exclude_lines = [
    'no cov', # Custom marker to skip coverage
    'if __name__ == .__main__.:', # Script execution guard
    'if TYPE_CHECKING:', # Type checking imports and code
    'pass', # Empty pass statements
    'raise NotImplementedError', # Unimplemented method placeholders
    'raise ImportError', # Import error handling
    'except ImportError', # Import error handling
    'except KeyError', # Common error handling
    'except AttributeError', # Common error handling
    'except NotImplementedError', # Common error handling
]

[tool.coverage.run]
source_pkgs = ["brosh", "tests"]
branch = true # Measure branch coverage (if/else statements)
parallel = true # Support parallel test execution
omit = [
    "src/brosh/__about__.py",
]

#------------------------------------------------------------------------------
# MYPY CONFIGURATION
# Configuration for type checking with mypy.
#------------------------------------------------------------------------------

[tool.mypy]
python_version = "3.10"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true
disallow_incomplete_defs = true
check_untyped_defs = true
disallow_untyped_decorators = true
no_implicit_optional = true
warn_redundant_casts = true
warn_unused_ignores = true
warn_no_return = true
warn_unreachable = true

[[tool.mypy.overrides]]
module = ["tests.*"]
disallow_untyped_defs = false
disallow_incomplete_defs = false

#------------------------------------------------------------------------------
# PYTEST CONFIGURATION
# Configuration for pytest, including markers, options, and benchmark settings.
#------------------------------------------------------------------------------

[tool.pytest.ini_options]
addopts = "-v --durations=10 -p no:briefcase"
asyncio_mode = "auto"
asyncio_default_fixture_loop_scope = "function"
console_output_style = "progress"
filterwarnings = ["ignore::DeprecationWarning", "ignore::UserWarning"]
log_cli = true
log_cli_level = "INFO"
markers = [
    "benchmark: marks tests as benchmarks (select with '-m benchmark')",
    "unit: mark a test as a unit test",
    "integration: mark a test as an integration test",
    "permutation: tests for permutation functionality", 
    "parameter: tests for parameter parsing",
    "prompt: tests for prompt parsing",
]
norecursedirs = [
    ".*",
    "build",
    "dist", 
    "venv",
    "__pycache__",
    "*.egg-info",
    "_private",
]
python_classes = ["Test*"]
python_files = ["test_*.py"]
python_functions = ["test_*"]
testpaths = ["tests"]

[tool.pytest-benchmark]
min_rounds = 100
min_time = 0.1
histogram = true
storage = "file"
save-data = true
compare = [
    "min",    # Minimum time
    "max",    # Maximum time
    "mean",   # Mean time
    "stddev", # Standard deviation
    "median", # Median time
    "iqr",    # Inter-quartile range
    "ops",    # Operations per second
    "rounds", # Number of rounds
]

#------------------------------------------------------------------------------
# RUFF CONFIGURATION
# Configuration for Ruff, including linter and formatter settings.
#------------------------------------------------------------------------------ 

# Ruff linter and formatter configuration
[tool.ruff]
target-version = "py310"
line-length = 120

# Linting rules configuration
[tool.ruff.lint]
# Rule sets to enable, organized by category
select = [
    # flake8 plugins and extensions
    'A', # flake8-builtins: checks for shadowed builtins
    'ARG', # flake8-unused-arguments: checks for unused function arguments
    'ASYNC', # flake8-async: checks for async/await issues
    'B', # flake8-bugbear: finds likely bugs and design problems
    'C', # flake8-comprehensions: helps write better list/dict comprehensions
    'DTZ', # flake8-datetimez: checks for datetime timezone issues
    'E', # pycodestyle errors: PEP 8 style guide errors
    'EM', # flake8-errmsg: checks for better error messages
    'F', # pyflakes: detects various errors
    'FBT', # flake8-boolean-trap: checks for boolean traps in function signatures
    'I', # isort: sorts imports
    'ICN', # flake8-import-conventions: checks for import conventions
    'ISC', # flake8-implicit-str-concat: checks for implicit string concatenation
    'LOG', # flake8-logging: checks for logging issues
    'N', # pep8-naming: checks naming conventions
    'PLC', # pylint convention: checks for convention issues
    'PLE', # pylint error: checks for errors
    'PLR', # pylint refactor: suggests refactors
    'PLW', # pylint warning: checks for suspicious code
    'PT', # flake8-pytest-style: checks pytest-specific style
    'PTH', # flake8-use-pathlib: checks for stdlib path usage vs pathlib
    'PYI', # flake8-pyi: checks stub files
    'RET', # flake8-return: checks return statement consistency
    'RSE', # flake8-raise: checks raise statements
    'RUF', # Ruff-specific rules
    'S', # flake8-bandit: checks for security issues
    'SIM', # flake8-simplify: checks for code simplification opportunities
    'T', # flake8-print: checks for print statements
    'TCH', # flake8-type-checking: helps with type-checking
    'TID', # flake8-tidy-imports: checks for tidy import statements
    'UP', # pyupgrade: checks for opportunities to use newer Python features
    'W', # pycodestyle warnings: PEP 8 style guide warnings
    'YTT', # flake8-2020: checks for misuse of sys.version or sys.version_info

]
# Rules to ignore (with reasons)
ignore = [
    'B027', # Empty method in abstract base class - sometimes needed for interfaces
    'C901', # Function is too complex - sometimes complexity is necessary
    'FBT003', # Boolean positional argument in function definition - sometimes unavoidable
    'PLR0911', # Too many return statements - sometimes needed for readability
    'PLR0912', # Too many branches - sometimes needed for complex logic
    'PLR0913', # Too many arguments - sometimes needed in APIs
    'PLR0915', # Too many statements - sometimes needed for comprehensive functions
    'PLR1714', # Consider merging multiple comparisons - sometimes less readable
    'PLW0603', # Using the global statement - sometimes necessary
    'PT013', # Pytest explicit test parameter - sometimes clearer
    'PTH123', # Path traversal - sometimes needed
    'PYI056', # Calling open() in pyi file - sometimes needed in type stubs
    'S105', # Possible hardcoded password - often false positives
    'S106', # Possible hardcoded password - often false positives
    'S107', # Possible hardcoded password - often false positives
    'S110', # try-except-pass - sometimes valid for suppressing exceptions
    'SIM102'
    # Nested if statements - sometimes more readable than combined conditions
]
# Rules that should not be automatically fixed
unfixable = [
    'F401', # Don't automatically remove unused imports - may be needed later

]
# Configure extend-exclude to ignore specific directories
extend-exclude = [".git", ".venv", "venv", "dist", "build"]

# isort configuration within Ruff
[tool.ruff.lint.isort]
known-first-party = ['brosh'] # Treat as first-party imports for sorting

# flake8-tidy-imports configuration within Ruff
[tool.ruff.lint.flake8-tidy-imports]
ban-relative-imports = 'all' # Ban all relative imports for consistency

# Per-file rule exceptions
[tool.ruff.lint.per-file-ignores]
# Tests can use magic values, assertions, and relative imports
'tests/**/*' = [
    'PLR2004', # Allow magic values in tests for readability
    'S101', # Allow assertions in tests
    'TID252'
    # Allow relative imports in tests for convenience
]
</file>

<file path="README.md">
# brosh - Browser Screenshot Tool

A powerful browser screenshot tool that captures scrolling screenshots of webpages using Playwright's async API. Supports intelligent section identification, multiple output formats including animated PNG, and MCP (Model Context Protocol) integration.

## Features

- **Async Playwright Integration**: Fast and reliable browser automation
- **Smart Section Detection**: Automatically identifies visible sections for descriptive filenames
- **Multiple Formats**: PNG, JPG, and animated PNG (APNG) output
- **Browser Support**: Chrome, Edge, and Safari (macOS)
- **Remote Debugging**: Connects to existing browser sessions preserving cookies/auth
- **MCP Server**: Integrate with AI tools via Model Context Protocol
- **HTML Extraction**: Optionally capture HTML content of visible elements
- **Flexible Scrolling**: Configurable scroll steps and starting positions

## Installation

```bash
uv pip install --system brosh
```

Or install from source:

```bash
git clone https://github.com/twardoch/brosh.git
cd brosh
pip install -e .[all]
```

## Usage

### Command Line Interface

#### Basic screenshot capture

```bash
# Capture a webpage
brosh shot "https://example.com"

# Capture with custom settings
brosh --width 1920 --height 1080 shot "https://example.com" --scroll_step 80 --format png

# Capture entire page height
brosh --height -1 shot "https://example.com"

# Create animated PNG of the scroll
brosh shot "https://example.com" --format apng --anim_spf 0.5
```

#### Browser management

```bash
# Start browser in debug mode (recommended for better performance)
brosh --app chrome run

# Quit browser
brosh --app chrome quit
```

#### Advanced options

```bash
# Start capture from a specific element
brosh shot "https://example.com" --from_selector "#main-content"

# Limit number of screenshots
brosh shot "https://example.com" --max_frames 5

# Scale output images
brosh shot "https://example.com" --scale 50

# Organize by domain
brosh --subdirs shot "https://example.com"

# Get HTML content with screenshots
brosh shot "https://example.com" --html --json
```

### MCP Server Mode

Run as an MCP server for integration with AI tools:

```bash
brosh-mcp
```

Or via the main command:

```bash
brosh mcp
```

### Python API

```python
import asyncio
from brosh import BrowserScreenshotTool

async def capture_screenshots():
    tool = BrowserScreenshotTool()
    
    # Basic capture
    screenshots = await tool.capture(
        url="https://example.com",
        width=1920,
        height=1080,
        scroll_step=100,
        format="png"
    )
    
    # Capture with HTML extraction
    result = await tool.capture(
        url="https://example.com",
        html=True,
        max_frames=3
    )
    
    # result is a dict with paths as keys and HTML/selectors as values
    for path, data in result.items():
        print(f"Screenshot: {path}")
        print(f"Selector: {data['selector']}")
        print(f"HTML: {data['html'][:100]}...")

asyncio.run(capture_screenshots())
```

## Command Options

### Global Options
- `--app`: Browser to use (chrome, edge, safari). Default: auto-detect
- `--width`: Viewport width in pixels. Default: screen width
- `--height`: Viewport height in pixels. Use -1 for full page. Default: screen height
- `--zoom`: Zoom level percentage. Default: 100
- `--output_dir`: Output directory. Default: Pictures folder
- `--subdirs`: Create subdirectories for each domain
- `--verbose`: Enable debug logging

### Shot Command Options
- `url`: URL to capture (required)
- `--scroll_step`: Scroll step as percentage of viewport height. Default: 100
- `--scale`: Scale output images by percentage. Default: 100
- `--format`: Output format (png, jpg, apng). Default: png
- `--anim_spf`: Seconds per frame for APNG. Default: 0.5
- `--html`: Extract HTML content of visible elements
- `--json`: Output results as JSON
- `--max_frames`: Maximum number of screenshots. Default: 0 (all)
- `--from_selector`: CSS selector to start capture from

## Output

Screenshots are saved with descriptive filenames:
```
domain-timestamp-scrollposition-section.png
```

For example:
```
github_com-241206-143022-00123-readme.png
```

## Development

This project uses [Hatch](https://hatch.pypa.io/) for development workflow management.

### Setup Development Environment

```bash
# Install hatch if you haven't already
pip install hatch

# Create and activate development environment
hatch shell

# Install development dependencies
pip install -e ".[dev,test]"

# Run tests
hatch run test

# Run linting and formatting
hatch run lint
hatch run fmt
```

### Running Tests

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=src/brosh

# Run specific test
pytest tests/test_capture.py
```

## Architecture

The project is organized into modular components:

- `browser.py`: Browser detection, launching, and management
- `capture.py`: Screenshot capture logic and page scrolling
- `image.py`: Image processing (scaling, format conversion, APNG creation)
- `tool.py`: Main tool orchestration
- `cli.py`: Command-line interface
- `mcp.py`: MCP server implementation

## License

MIT License

## Credits

- Created by Adam Twardoch
- Developed using Anthropic software
</file>

</files>
